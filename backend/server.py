from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

import cv2
import time

from detector import YoloDetector
from stats_manager import StatsManager
from alert_manager import AlertManager


# ğŸ”¹ FastAPI app
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all ports (5173, 5174, etc.)
    # allow_origins=[
    #     "http://localhost:5173",
    #     "http://127.0.0.1:5173",
    # ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ”¹ Core components
detector = YoloDetector()
stats = StatsManager()
alert_manager = AlertManager()

# ğŸ”¹ Camera (open once, globally)
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)


def generate_frames():
    """
    Robust MJPEG stream generator.
    NEVER breaks the stream.
    Survives camera hiccups and model errors.
    """
    while True:
        try:
            success, frame = cap.read()

            # â— NEVER break a streaming generator
            if not success or frame is None:
                time.sleep(0.05)
                continue

            # ğŸ”¹ Detect + track objects
            detections = detector.detect(frame)

            # ğŸ”¹ Determine what is currently active (visible)
            current_active = set()
            for d in detections:
                cat = stats.classify(d["label"])
                current_active.add(cat)
                # DEBUG PRINT: Check what label is seeing
                print(f"DEBUG: Label='{d['label']}' -> Category='{cat}'")
            
            stats.set_active(current_active)

            # ğŸ”¹ Update global statistics
            stats.update(detections)

            # ğŸ”¹ Handle alerts + draw boxes
            for d in detections:
                category = stats.classify(d["label"])

                # ğŸš¨ Trigger email alert if needed
                alert_manager.handle_detection(d, category)

                # ğŸ¨ Draw bounding box
                x1, y1, x2, y2 = d["bbox"]
                label = f"{d['label']} #{d['id']} ({category})"

                # Color coding (OpenCV uses BGR)
                if category == "recyclable":
                    color = (0, 255, 0)    # Green
                elif category == "toxic":
                    color = (0, 0, 255)    # Red
                elif category == "human":
                    color = (0, 255, 255)  # Yellow (Mix of Green+Red)
                else:
                    color = (200, 200, 200) # Grey/White for others

                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
                cv2.putText(
                    frame,
                    label,
                    (x1, max(y1 - 10, 20)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    color,
                    2
                )

            # ğŸ”¹ Encode frame as JPEG
            ret, buffer = cv2.imencode(".jpg", frame)
            if not ret:
                continue

            frame_bytes = buffer.tobytes()

            # ğŸ”¹ MJPEG chunk
            yield (
                b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" +
                frame_bytes +
                b"\r\n"
            )

        except Exception as e:
            # â— NEVER crash the stream
            print("âš ï¸ Video stream error:", e)
            time.sleep(0.05)
            continue


# ğŸ¥ Live video endpoint
@app.get("/video")
def video():
    return StreamingResponse(
        generate_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )


# ğŸ“Š Live statistics endpoint
@app.get("/stats")
def get_stats():
    return stats.get_stats()


# ğŸš¨ Last alert endpoint
@app.get("/alert")
def get_alert():
    return alert_manager.get_last_alert()
